{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(a):\n",
    "    return a.reshape(a.shape[0], 3, 32, 32).mean(1).reshape(a.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    imgs = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    grayscale_imgs = imgs.mean(1)\n",
    "    cropped_imgs = grayscale_imgs[:, 4:28, 4:28]\n",
    "    img_data = cropped_imgs.reshape(data.shape[0], -1)\n",
    "    img_size = np.shape(img_data)[1]\n",
    "    means = np.mean(img_data, axis=1)\n",
    "    meansT = means.reshape(len(means), 1)\n",
    "    stds = np.std(img_data, axis=1)\n",
    "    stdsT = stds.reshape(len(stds), 1)\n",
    "    adj_stds = np.maximum(stdsT, 1.0 / np.sqrt(img_size))\n",
    "    normalized = (img_data - meansT) / adj_stds\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(directory):\n",
    "    names = unpickle('{}/batches.meta'.format(directory))['label_names']\n",
    "    print('names', names)\n",
    "    data, labels = [], []\n",
    "    for i in range(1, 6):\n",
    "        filename = '{}/data_batch_{}'.format(directory, i)\n",
    "        batch_data = unpickle(filename)\n",
    "        if len(data) > 0:\n",
    "            data = np.vstack((data, batch_data['data']))\n",
    "            labels = np.hstack((labels, batch_data['labels']))\n",
    "        else:\n",
    "            data = batch_data['data']\n",
    "            labels = batch_data['labels']\n",
    "    print(np.shape(data), np.shape(labels))\n",
    "    data = clean(data)\n",
    "    data = data.astype(np.float32)\n",
    "    return names, data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "(50000, 3072) (50000,)\n",
      "WARNING:tensorflow:From /Users/mattmann/git/buildout.python/python-3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "names, data, labels = read_data('./cifar-10-batches-py')\n",
    "x = tf.placeholder(tf.float32, [None, 24 * 24]) # 5000,576\n",
    "y = tf.placeholder(tf.float32, [None, len(names)]) # 50000, 10\n",
    "W1 = tf.Variable(tf.random_normal([5, 5, 1, 64])) # first convo layer with 64 filters size 5x5, one band greyscale, image input size 24x24\n",
    "b1 = tf.Variable(tf.random_normal([64])) # biases for first convo layer\n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 64, 64])) # second convo layer with 64 filters size 5x5, run on the 64 outputs of first layer, image input size 12x12\n",
    "b2 = tf.Variable(tf.random_normal([64])) # biases for the second convo layer\n",
    "W3 = tf.Variable(tf.random_normal([6*6*64, 1024])) # fully connected layer taking output of convo layer which are 64 image inputs size 6x6 and mapping to 32x32 original image \n",
    "b3 = tf.Variable(tf.random_normal([1024])) # biases for fully connected layer\n",
    "W_out = tf.Variable(tf.random_normal([1024, len(names)])) # output weights for final layer of actual labels, 1024 features  mapped to 10 labels one hot encoded\n",
    "b_out = tf.Variable(tf.random_normal([len(names)])) # biases for output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(x, W, b):\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    conv_with_b = tf.nn.bias_add(conv, b)\n",
    "    conv_out = tf.nn.relu(conv_with_b)\n",
    "    return conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_layer(conv, k=2):\n",
    "    return tf.nn.max_pool(conv, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "     padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    x_reshaped = tf.reshape(x, shape=[-1, 24, 24, 1])\n",
    "    conv_out1 = conv_layer(x_reshaped, W1, b1)\n",
    "    maxpool_out1 = maxpool_layer(conv_out1)\n",
    "    norm1 = tf.nn.lrn(maxpool_out1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    conv_out2 = conv_layer(norm1, W2, b2)\n",
    "    norm2 = tf.nn.lrn(conv_out2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    maxpool_out2 = maxpool_layer(norm2)\n",
    "    maxpool_reshaped = tf.reshape(maxpool_out2, [-1, W3.get_shape().as_list()[0]])\n",
    "    local = tf.add(tf.matmul(maxpool_reshaped, W3), b3)\n",
    "    local_out = tf.nn.relu(local)\n",
    "    out = tf.add(tf.matmul(local_out, W_out), b_out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-934bb6e9a2fc>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_op = model()\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model_op, labels=y))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "correct_pred = tf.equal(tf.argmax(model_op, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5fde29080645feaff2148cd61a4dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.224\n",
      "1 0.252\n",
      "2 0.248\n",
      "3 0.256\n",
      "4 0.268\n",
      "5 0.292\n",
      "6 0.276\n",
      "7 0.3\n",
      "8 0.332\n",
      "9 0.324\n",
      "10 0.336\n",
      "11 0.344\n",
      "12 0.352\n",
      "13 0.36\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    onehot_labels = tf.one_hot(labels, len(names), on_value=1., off_value=0., axis=-1)\n",
    "    onehot_vals = sess.run(onehot_labels)\n",
    "    batch_size = len(data) // 200\n",
    "    print('batch size', batch_size)\n",
    "    for j in tqdm(range(0, 1000)):\n",
    "        #print('EPOCH', j)\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch_data = data[i:i+batch_size, :]\n",
    "            batch_onehot_vals = onehot_vals[i:i+batch_size, :]\n",
    "            _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x:batch_data, y: batch_onehot_vals})\n",
    "            #if i % 1000 == 0:\n",
    "            #    print(i, accuracy_val)\n",
    "        #print('DONE WITH EPOCH')\n",
    "        print(j, accuracy_val)\n",
    "        \n",
    "\n",
    "    saver.save(sess, './cifar10-cnn-tf1n-1000epochs.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_X(x, W1, b1, W2, b2, W3, b3, W_out, b_out):\n",
    "    x_reshaped = tf.reshape(x, shape=[-1, 24, 24, 1])\n",
    "    conv_out1 = conv_layer(x_reshaped, W1, b1)\n",
    "    maxpool_out1 = maxpool_layer(conv_out1)\n",
    "    norm1 = tf.nn.lrn(maxpool_out1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    conv_out2 = conv_layer(norm1, W2, b2)\n",
    "    norm2 = tf.nn.lrn(conv_out2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    maxpool_out2 = maxpool_layer(norm2)\n",
    "    maxpool_reshaped = tf.reshape(maxpool_out2, [-1, W3.shape[0]])\n",
    "    local = tf.add(tf.matmul(maxpool_reshaped, W3), b3)\n",
    "    local_out = tf.nn.relu(local)\n",
    "    out = tf.add(tf.matmul(local_out, W_out), b_out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_data):\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, \"./cifar10-cnn-tf1n-1000epochs.ckpt\")\n",
    "        print(\"Model restored.\")\n",
    "        W1_val = W1.eval()\n",
    "        b1_val = b1.eval()\n",
    "        W2_val = W2.eval()\n",
    "        b2_val = b2.eval()\n",
    "        W3_val = W3.eval()\n",
    "        b3_val = b3.eval()\n",
    "        W_out_val = W_out.eval()\n",
    "        b_out_val = b_out.eval()\n",
    "        model_x_out = model_X(img_data, W1_val, b1_val, W2_val, b2_val, W3_val, b3_val, W_out_val, b_out_val)\n",
    "        class_num = np.argmax(model_x_out.eval(), axis=1)[0]\n",
    "        class_name = names[np.argmax(model_x_out.eval(), axis=1)[0]]\n",
    "        return (class_num, class_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num, class_name = predict(data[3])\n",
    "print('Class Num', class_num)\n",
    "print('Class', class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(class_name)\n",
    "img = np.reshape(data[3, :], (24,24))\n",
    "plt.imshow(img, cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out on test images\n",
    "def read_test_data(directory):\n",
    "    names = unpickle('{}/batches.meta'.format(directory))['label_names']\n",
    "    print('names', names)\n",
    "    data, labels = [], []\n",
    "    \n",
    "    filename = '{}/test_batch'.format(directory)\n",
    "    batch_data = unpickle(filename)\n",
    "    if len(data) > 0:\n",
    "        data = np.vstack((data, batch_data['data']))\n",
    "        labels = np.hstack((labels, batch_data['labels']))\n",
    "    else:\n",
    "        data = batch_data['data']\n",
    "        labels = batch_data['labels']\n",
    "    print(np.shape(data), np.shape(labels))\n",
    "    data = clean(data)\n",
    "    data = data.astype(np.float32)\n",
    "    return names, data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names, test_data, test_labels = read_test_data('cifar-10-batches-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class_num, test_class_name = predict(test_data[4])\n",
    "print('Test Class Num', test_class_num)\n",
    "print('Test Class Name', test_class_name)\n",
    "print('Actual Class Label', test_labels[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(test_class_name)\n",
    "img = np.reshape(test_data[3, :], (24,24))\n",
    "plt.imshow(img, cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_accuracy(test_data, test_names, test_labels):\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, \"./cifar10-cnn-tf1n-1000epochs.ckpt\")\n",
    "        print(\"Model restored.\")\n",
    "        W1_val = W1.eval()\n",
    "        b1_val = b1.eval()\n",
    "        W2_val = W2.eval()\n",
    "        b2_val = b2.eval()\n",
    "        W3_val = W3.eval()\n",
    "        b3_val = b3.eval()\n",
    "        W_out_val = W_out.eval()\n",
    "        b_out_val = b_out.eval()\n",
    "        model_x_out = model_X(test_data, W1_val, b1_val, W2_val, b2_val, W3_val, b3_val, W_out_val, b_out_val)\n",
    "        \n",
    "        onehot_test_labels = tf.one_hot(test_labels, len(test_names), on_value=1., off_value=0., axis=-1)\n",
    "        test_correct_pred = tf.equal(tf.argmax(model_x_out, 1), tf.argmax(onehot_test_labels, 1))\n",
    "        test_accuracy = tf.reduce_mean(tf.cast(test_correct_pred, tf.float32))\n",
    "        \n",
    "        print('Test accuracy %f' % (test_accuracy.eval()))  \n",
    "        predictions = tf.argmax(model_x_out, 1).eval()\n",
    "        return (predictions, tf.cast(test_correct_pred, tf.float32).eval(), onehot_test_labels.eval())\n",
    "\n",
    "    \n",
    "predict_vals, test_correct_preds, onehot_test_lbls = get_test_accuracy(test_data, test_names, test_labels)\n",
    "print(predict_vals)\n",
    "print(predict_vals.shape)\n",
    "print(test_correct_preds)\n",
    "print(test_correct_preds.shape)\n",
    "print(onehot_test_lbls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_test = label_binarize(test_labels, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "predictions_test = label_binarize(predict_vals, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "#print(outcome_test.shape)\n",
    "#print(predictions_test.shape)\n",
    "#print(outcome_test)\n",
    "#print(predictions_test)\n",
    "n_classes = outcome_test.shape[1]\n",
    "#print(n_classes)\n",
    "\n",
    "#fpr, tpr, thresholds = roc_curve(predictions_test, outcome_test)\n",
    "#roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(outcome_test[:, i], predictions_test[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "   \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(outcome_test.ravel(), predictions_test.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for class: '+test_names[2])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                                   ''.format(test_names[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve for CIFAR-10 CNN 1000 iter Tensorflow (area = %{0:0.2f})'.format(roc_mean))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
